{
 "metadata": {
  "name": "Charlie Tang's deep svm"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "import itertools\n",
      "import gzip\n",
      "import time\n",
      "\n",
      "import numpy as np\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "\n",
      "import climin.stops\n",
      "import climin.initialize\n",
      "import climin.project\n",
      "import climin.schedule\n",
      "\n",
      "from brummlearn.pca import Pca\n",
      "from brummlearn.mlp import Mlp, DropoutMlp, dropout_optimizer_conf, FastDropoutNetwork\n",
      "from breze.component.loss import nce\n",
      "import breze.util\n",
      "\n",
      "import brummlearn.base\n",
      "from brummlearn.data import one_hot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafile = '../examples/mnist.pkl.gz'\n",
      "# Load data.                                                                                                   \n",
      "\n",
      "with gzip.open(datafile,'rb') as f:                                                                        \n",
      "    train_set, val_set, test_set = cPickle.load(f)                                                       \n",
      "\n",
      "X, Z = train_set                                                                                               \n",
      "VX, VZ = val_set\n",
      "TX, TZ = test_set\n",
      "\n",
      "Z = one_hot(Z, 10)\n",
      "VZ = one_hot(VZ, 10)\n",
      "TZ = one_hot(TZ, 10)\n",
      "\n",
      "Z = (Z * 2) - 1\n",
      "TZ = (TZ * 2) - 1\n",
      "VZ = (VZ * 2) - 1\n",
      "\n",
      "image_dims = 28, 28\n",
      "\n",
      "pca = Pca(70)\n",
      "pca.fit(X)\n",
      "X, VX, TX = [pca.transform(i) for i in (X, VX, TX)]\n",
      "\n",
      "X = np.concatenate([X, VX], axis=0)\n",
      "Z = np.concatenate([Z, VZ], axis=0)\n",
      "\n",
      "X, Z, TX, TZ = [brummlearn.base.cast_array_to_local_type(i) for i in (X, Z, TX, TZ)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def squared_hinge(target, prediction):\n",
      "    return (T.maximum(1 - target * prediction, 0) ** 2)\n",
      "\n",
      "class TangMlp(Mlp):\n",
      "    \n",
      "    def __init__(\n",
      "        self, n_inpt, n_hiddens, n_output, hidden_transfers, out_transfer, loss, optimizer, batch_size, noise_schedule,\n",
      "        max_iter=1000, verbose=False):\n",
      "        super(TangMlp, self).__init__(n_inpt, n_hiddens, n_output, hidden_transfers, out_transfer, loss, optimizer, batch_size,\n",
      "            max_iter, verbose)\n",
      "        \n",
      "        self.noise_schedule = noise_schedule\n",
      "    \n",
      "    def _make_args(self, X, Z):\n",
      "        args = super(TangMlp, self)._make_args(X, Z)\n",
      "        def corrupt(x, level):\n",
      "            return x + np.random.normal(0, level, x.shape).astype(theano.config.floatX)\n",
      "        return (((corrupt(x, n), z), k) for n, ((x, z), k) in itertools.izip(self.noise_schedule, args))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_passes = 400\n",
      "batch_size = 200\n",
      "max_iter = max_passes * X.shape[0] / batch_size\n",
      "n_report = X.shape[0] / batch_size\n",
      "\n",
      "noise_schedule = (1 - float(i) / max_iter for i in xrange(max_iter)) \n",
      "noise_schedule = itertools.chain(noise_schedule, itertools.repeat(0))\n",
      "\n",
      "stop = climin.stops.any_([\n",
      "    climin.stops.after_n_iterations(max_iter),\n",
      "    ])\n",
      "\n",
      "pause = climin.stops.modulo_n_iterations(n_report)\n",
      "\n",
      "optimizer = 'rmsprop', {'steprate': 0.001, 'momentum': 0.9, 'decay': 0.9, 'step_adapt': 0.01}\n",
      "#optimizer = 'gd', {'steprate': climin.schedule.linear_annealing(0.1, 0, max_iter), 'momentum': 0.5, 'momentum_type': 'nesterov'}\n",
      "#optimizer = dropout_optimizer_conf(steprate_0=1, n_repeats=1)\n",
      "m = TangMlp(X.shape[1], [512, 512], 10, hidden_transfers=['sigmoid', 'sigmoid'], out_transfer='identity', loss=squared_hinge, noise_schedule=noise_schedule, optimizer=optimizer, batch_size=batch_size, max_iter=max_iter)\n",
      "climin.initialize.randomize_normal(m.parameters.data, 0, 0.02)\n",
      "m.parameters['out_bias'][...] = 0\n",
      "\n",
      "weight_decay = ((m.parameters.hidden_to_out ** 2).sum())\n",
      "#                + (m.parameters.hidden_to_hidden_0**2).sum()\n",
      "#                + (m.parameters.hidden_to_out**2).sum())\n",
      "weight_decay /= m.exprs['inpt'].shape[0]\n",
      "m.exprs['true_loss'] = m.exprs['loss']\n",
      "c_wd = 0.001\n",
      "m.exprs['loss'] = m.exprs['loss'] + c_wd * weight_decay\n",
      "\n",
      "f_wd = m.function(['inpt'], c_wd * weight_decay)\n",
      "n_wrong = 1 - T.eq(T.argmax(m.exprs['output'], axis=1), T.argmax(m.exprs['target'], axis=1)).mean()\n",
      "f_n_wrong = m.function(['inpt', 'target'], n_wrong)\n",
      "                \n",
      "losses = []\n",
      "v_losses = []\n",
      "print 'max iter', max_iter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "max iter 120000\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "# Set up a nice printout.\n",
      "keys = '#', 'loss', 'val loss', 'seconds', 'wd', 'train emp', 'test emp'\n",
      "max_len = max(len(i) for i in keys)\n",
      "header = '\\t'.join(i for i in keys)\n",
      "print header\n",
      "print '-' * len(header)\n",
      "\n",
      "f_loss = m.function(['inpt', 'target'], ['true_loss', 'loss'])\n",
      "\n",
      "for i, info in enumerate(m.powerfit((X, Z), (TX, TZ), stop, pause)):\n",
      "    if info['n_iter'] % n_report != 0:\n",
      "        continue\n",
      "    passed = time.time() - start\n",
      "    losses.append(info['loss'])\n",
      "    v_losses.append(info['val_loss'])\n",
      "    \n",
      "    #img = tile_raster_images(fe.parameters['in_to_hidden'].T, image_dims, feature_dims, (1, 1))\n",
      "    #save_and_display(img, 'filters-%i.png' % i)  \n",
      "    info.update({\n",
      "        'time': passed,\n",
      "        'l2-loss': f_wd(X),\n",
      "        'train_emp': f_n_wrong(X, Z),\n",
      "        'test_emp': f_n_wrong(TX, TZ),\n",
      "    })\n",
      "    row = '%(n_iter)i\\t%(loss)g\\t%(val_loss)g\\t%(time)g\\t%(l2-loss)g\\t%(train_emp)g\\t%(test_emp)g' % info\n",
      "    print row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#\tloss\tval loss\tseconds\twd\ttrain emp\ttest emp\n",
        "---------------------------------------------\n",
        "0\t6.80059\t6.79592\t3.77655\t3.34922e-08\t0.9007\t0.8968"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "300\t0.89293\t0.849043\t11.2762\t2.91075e-07\t0.127817\t0.1205"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "600\t0.482689\t0.462047\t18.807\t1.07246e-06\t0.0698167\t0.0671"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "900\t0.354671\t0.35114\t26.3243\t1.97359e-06\t0.0513167\t0.0501"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1200\t0.309708\t0.309624\t33.8222\t2.91137e-06\t0.0422333\t0.0405"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1500\t0.282444\t0.279963\t41.3418\t3.70927e-06\t0.0401167\t0.0397"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1800\t0.286735\t0.280759\t48.8523\t4.38193e-06\t0.0419167\t0.0421"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2100\t0.273392\t0.274246\t56.4048\t5.00739e-06\t0.03875\t0.0383"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m.predict(X[:1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([[ 4.1872654 ,  7.29619551,  5.38406849,  4.66654682,  3.16716623,\n",
        "         4.0718689 ,  3.28585577,  4.94428635,  5.95642281,  3.70639229]], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m.parameters['out_bias']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "array([ 0.03482761,  0.06090129,  0.04329228,  0.03862644,  0.02350282,\n",
        "        0.03161389,  0.02433921,  0.03963067,  0.0492355 ,  0.02974045], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}