{
 "metadata": {
  "name": "MLP on MNIST"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "import gzip\n",
      "import time\n",
      "\n",
      "import numpy as np\n",
      "import theano.tensor as T\n",
      "\n",
      "import climin.stops\n",
      "import climin.initialize\n",
      "\n",
      "from brummlearn.mlp import Mlp, DropoutMlp, truncate, dropout_optimizer_conf\n",
      "from brummlearn.data import one_hot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prepare Data\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafile = '../examples/mnist.pkl.gz'\n",
      "# Load data.                                                                                                   \n",
      "\n",
      "with gzip.open(datafile,'rb') as f:                                                                        \n",
      "    train_set, val_set, test_set = cPickle.load(f)                                                       \n",
      "\n",
      "X, Z = train_set                                                                                               \n",
      "VX, VZ = val_set\n",
      "TX, TZ = test_set\n",
      "\n",
      "Z = one_hot(Z, 10)\n",
      "VZ = one_hot(VZ, 10)\n",
      "TZ = one_hot(TZ, 10)\n",
      "\n",
      "image_dims = 28, 28"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define Model\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "max_passes = 100\n",
      "batch_size = 250\n",
      "max_iter = max_passes * X.shape[0] / batch_size\n",
      "n_report = X.shape[0] / batch_size\n",
      "\n",
      "stop = climin.stops.any_([\n",
      "    climin.stops.after_n_iterations(max_iter),\n",
      "    ])\n",
      "\n",
      "pause = climin.stops.modulo_n_iterations(n_report)\n",
      "\n",
      "optimizer = 'rmsprop', {'steprate': 0.001, 'momentum': 0.9, 'decay': 0.9, 'step_adapt': 0.01}\n",
      "#optimizer = dropout_optimizer_conf(steprate_0=1, n_repeats=1)\n",
      "m = DropoutMlp(784, [512, 512], 10, max_norm=15, hidden_transfers=['sigmoid', 'sigmoid'], out_transfer='softmax', loss='nce', optimizer=optimizer, batch_size=batch_size, max_iter=max_iter)\n",
      "m.parameters.data[...] = np.random.normal(0, 1, m.parameters.data.shape)\n",
      "\n",
      "weight_decay = ((m.parameters.in_to_hidden**2).sum()\n",
      "                + (m.parameters.hidden_to_hidden_0**2).sum()\n",
      "                + (m.parameters.hidden_to_out**2).sum())\n",
      "weight_decay /= m.exprs['inpt'].shape[0]\n",
      "m.exprs['true_loss'] = m.exprs['loss']\n",
      "c_wd = 0.00001\n",
      "m.exprs['loss'] = m.exprs['loss'] + c_wd * weight_decay\n",
      "\n",
      "f_wd = m.function(['inpt'], c_wd * weight_decay)\n",
      "n_wrong = 1 - T.eq(T.argmax(m.exprs['output'], axis=1), T.argmax(m.exprs['target'], axis=1)).mean()\n",
      "f_n_wrong = m.function(['inpt', 'target'], n_wrong)\n",
      "                \n",
      "losses = []\n",
      "v_losses = []\n",
      "print 'max iter', max_iter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Learn\n",
      "=====\n",
      "\n",
      "First train an report validation error to manually check for the training error at which validation error is minimal."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "# Set up a nice printout.\n",
      "keys = '#', 'loss', 'val loss', 'seconds', 'wd', 'train emp', 'val emp'\n",
      "max_len = max(len(i) for i in keys)\n",
      "header = '\\t'.join(i for i in keys)\n",
      "print header\n",
      "print '-' * len(header)\n",
      "\n",
      "f_loss = m.function(['inpt', 'target'], ['true_loss', 'loss'])\n",
      "\n",
      "for i, info in enumerate(m.powerfit((X, Z), (VX, VZ), stop, pause)):\n",
      "    if info['n_iter'] % n_report != 0:\n",
      "        continue\n",
      "    passed = time.time() - start\n",
      "    losses.append(info['loss'])\n",
      "    v_losses.append(info['val_loss'])\n",
      "    \n",
      "    #img = tile_raster_images(fe.parameters['in_to_hidden'].T, image_dims, feature_dims, (1, 1))\n",
      "    #save_and_display(img, 'filters-%i.png' % i)  \n",
      "    info.update({\n",
      "        'time': passed,\n",
      "        'l2-loss': f_wd(X),\n",
      "        'train_emp': f_n_wrong(X, Z),\n",
      "        'val_emp': f_n_wrong(VX, VZ),\n",
      "    })\n",
      "    row = '%(n_iter)i\\t%(loss)g\\t%(val_loss)g\\t%(time)g\\t%(l2-loss)g\\t%(train_emp)g\\t%(val_emp)g' % info\n",
      "    print row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m.parameters.data[...] = info['best_pars']\n",
      "m.parameters['in_to_hidden'] *= 0.8\n",
      "m.parameters['hidden_to_hidden_0'] *= 0.5\n",
      "m.parameters['hidden_to_out'] *= 0.5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Final Training\n",
      "--------------\n",
      "Train on train+validation until the training error passes a threshold."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "m.parameters.data[...] = np.random.normal(0, 1e-3, m.parameters.data.shape)\n",
      "\n",
      "start = time.time()\n",
      "# Set up a nice printout.\n",
      "keys = '#', 'loss', 'val loss', 'seconds'#, 'step_length'\n",
      "max_len = max(len(i) for i in keys)\n",
      "header = '   '.join(i.ljust(max_len) for i in keys)\n",
      "print header\n",
      "print '-' * len(header)\n",
      "\n",
      "RVX = np.concatenate([X, VX], axis=0)\n",
      "RVZ = np.concatenate([Z, VZ], axis=0)\n",
      "\n",
      "for i, info in enumerate(m.powerfit((RVX, RVZ), (VX, VZ), stop, pause)):\n",
      "    passed = time.time() - start\n",
      "    losses.append(info['loss'])\n",
      "    v_losses.append(info['val_loss'])\n",
      "    \n",
      "    row = '%i' % info['n_iter'], '%.6f' % info['loss'], '%.6f' % info['val_loss'], '%.3f' % passed#, '%.6f' % info['step_length']\n",
      "    print '   '.join(i.ljust(max_len) for i in row)\n",
      "\n",
      "    if losses[-1] <= 0.023:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_predict = m.function(['inpt'], T.argmax(m.exprs['output_in'], axis=1))\n",
      "\n",
      "TY = f_predict(TX)\n",
      "\n",
      "print '#wrong', (TY != TZ.argmax(axis=1)).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#wrong 614\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}