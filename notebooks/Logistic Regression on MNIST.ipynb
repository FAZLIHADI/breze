{
 "metadata": {
  "name": "Logistic Regression on MNIST"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "import gzip\n",
      "\n",
      "import numpy as np\n",
      "import theano.tensor as T\n",
      "\n",
      "import climin.stops\n",
      "import climin.initialize\n",
      "\n",
      "from brummlearn.glm import GeneralizedLinearModel\n",
      "from brummlearn.data import one_hot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convenience function which is useful for learning: it has early stopping and\n",
      "# saves the best parameters of the validation set.\n",
      "\n",
      "def fit(X, Z, VX, VZ, model, stop, pause):\n",
      "    train_losses = []\n",
      "    val_losses = []\n",
      "    f_loss = model.function(['inpt', 'target'], 'loss')\n",
      "    \n",
      "    best_pars = None\n",
      "    best_loss = float('inf')\n",
      "\n",
      "    for info in model.iter_fit(X, Z):\n",
      "        if not pause(info):\n",
      "            continue\n",
      "        info['loss'] = f_loss(X, Z)\n",
      "        info['val_loss'] = f_loss(VX, VZ)\n",
      "        train_losses.append(info['loss'])\n",
      "        val_losses.append(info['val_loss'])\n",
      "        \n",
      "        if info['val_loss'] < best_loss:\n",
      "            best_loss = info['val_loss']\n",
      "            best_pars = model.parameters.data.copy()\n",
      "            \n",
      "        info['best_loss'] = best_loss\n",
      "        info['best_pars'] = best_pars\n",
      "        \n",
      "        yield info\n",
      "        if stop(info):\n",
      "            print 'stopping condition'\n",
      "            break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prepare Data\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafile = '../examples/mnist.pkl.gz'\n",
      "# Load data.                                                                                                   \n",
      "\n",
      "with gzip.open(datafile,'rb') as f:                                                                        \n",
      "    train_set, val_set, test_set = cPickle.load(f)                                                       \n",
      "\n",
      "X, Z = train_set                                                                                               \n",
      "VX, VZ = val_set\n",
      "TX, TZ = test_set\n",
      "\n",
      "Z = one_hot(Z, 10)\n",
      "VZ = one_hot(VZ, 10)\n",
      "TZ = one_hot(TZ, 10)\n",
      "\n",
      "image_dims = 28, 28"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define Model\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_passes = 1000\n",
      "batch_size = X.shape[0]\n",
      "max_iter = max_passes * X.shape[0] / batch_size\n",
      "\n",
      "stop = climin.stops.any_([\n",
      "    climin.stops.converged('loss'),\n",
      "    climin.stops.rising('val_loss', 10, 1e-5, patience=5),\n",
      "    climin.stops.after_n_iterations(max_iter),\n",
      "    ])\n",
      "\n",
      "pause = climin.stops.modulo_n_iterations(10)\n",
      "\n",
      "optimizer = 'lbfgs'\n",
      "m = GeneralizedLinearModel(784, 10, out_transfer='softmax', loss='nce', optimizer=optimizer, batch_size=batch_size, max_iter=max_iter)\n",
      "\n",
      "losses = []\n",
      "v_losses = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Learn\n",
      "====="
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up a nice printout.\n",
      "keys = '#', 'loss', 'val loss'#, 'step_length'\n",
      "max_len = max(len(i) for i in keys)\n",
      "header = '   '.join(i.ljust(max_len) for i in keys)\n",
      "print header\n",
      "print '-' * len(header)\n",
      "\n",
      "\n",
      "for i, info in enumerate(fit(X, Z, VX, VZ, m, stop, pause)):\n",
      "    losses.append(info['loss'])\n",
      "    v_losses.append(info['val_loss'])\n",
      "    \n",
      "    #img = tile_raster_images(fe.parameters['in_to_hidden'].T, image_dims, feature_dims, (1, 1))\n",
      "    #save_and_display(img, 'filters-%i.png' % i)  \n",
      "    \n",
      "    row = '%i' % i, '%.6f' % info['loss'], '%.6f' % info['val_loss']#, '%.6f' % info['step_length']\n",
      "    print '   '.join(i.ljust(max_len) for i in row)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#          loss       val loss\n",
        "------------------------------\n",
        "0          9.512222   9.260194"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1          1.126953   0.975016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2          0.630961   0.606985"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3          0.478327   0.460580"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4          0.410159   0.403372"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5          0.357310   0.365737"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6          0.328787   0.343182"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7          0.307101   0.333526"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8          0.289033   0.317889"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9          0.275792   0.311726"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10         0.264821   0.304389"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11         0.257657   0.299257"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12         0.250397   0.293375"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13         0.245638   0.289301"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14         0.241948   0.286701"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15         0.238747   0.286221"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16         0.235714   0.284811"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17         0.233102   0.282322"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18         0.230968   0.283010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19         0.228878   0.282391"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20         0.227015   0.282719"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21         0.225277   0.282854"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22         0.223805   0.284163"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23         0.222423   0.283351"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24         0.221288   0.283707"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25         0.220142   0.284684"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "26         0.219170   0.285491"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "stopping condition\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_predict = m.function(['inpt'], T.argmax(m.exprs['output_in'], axis=1))\n",
      "\n",
      "TY = f_predict(TX)\n",
      "\n",
      "print '#wrong', (TY != TZ.argmax(axis=1)).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#wrong 775\n"
       ]
      }
     ],
     "prompt_number": 6
    }
   ],
   "metadata": {}
  }
 ]
}