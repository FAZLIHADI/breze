{
 "metadata": {
  "name": "Logistic Regression on MNIST"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "import gzip\n",
      "\n",
      "import numpy as np\n",
      "import theano.tensor as T\n",
      "\n",
      "import climin.stops\n",
      "import climin.initialize\n",
      "\n",
      "from brummlearn.glm import GeneralizedLinearModel\n",
      "from brummlearn.data import one_hot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prepare Data\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafile = '../examples/mnist.pkl.gz'\n",
      "# Load data.                                                                                                   \n",
      "\n",
      "with gzip.open(datafile,'rb') as f:                                                                        \n",
      "    train_set, val_set, test_set = cPickle.load(f)                                                       \n",
      "\n",
      "X, Z = train_set                                                                                               \n",
      "VX, VZ = val_set\n",
      "TX, TZ = test_set\n",
      "\n",
      "Z = one_hot(Z, 10)\n",
      "VZ = one_hot(VZ, 10)\n",
      "TZ = one_hot(TZ, 10)\n",
      "\n",
      "image_dims = 28, 28"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define Model\n",
      "============"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_passes = 1000\n",
      "batch_size = 100\n",
      "max_iter = max_passes * X.shape[0] / batch_size\n",
      "\n",
      "stop = climin.stops.any_([\n",
      "    climin.stops.after_n_iterations(max_iter),\n",
      "    ])\n",
      "\n",
      "pause = climin.stops.modulo_n_iterations(100)\n",
      "\n",
      "optimizer = 'gd', {'steprate': 0.1, 'momentum': 0.9}\n",
      "m = GeneralizedLinearModel(784, 10, out_transfer='softmax', loss='nce', optimizer=optimizer, batch_size=batch_size, max_iter=max_iter)\n",
      "\n",
      "losses = []\n",
      "v_losses = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Learn\n",
      "====="
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up a nice printout.\n",
      "keys = '#', 'loss', 'val loss'#, 'step_length'\n",
      "max_len = max(len(i) for i in keys)\n",
      "header = '   '.join(i.ljust(max_len) for i in keys)\n",
      "print header\n",
      "print '-' * len(header)\n",
      "\n",
      "import time\n",
      "start = time.time()\n",
      "\n",
      "for i, info in enumerate(m.powerfit((X, Z), (VX, VZ), stop, pause)):\n",
      "    losses.append(info['loss'])\n",
      "    v_losses.append(info['val_loss'])\n",
      "    \n",
      "    #img = tile_raster_images(fe.parameters['in_to_hidden'].T, image_dims, feature_dims, (1, 1))\n",
      "    #save_and_display(img, 'filters-%i.png' % i)  \n",
      "    \n",
      "    row = '%i' % i, '%.6f' % info['loss'], '%.6f' % info['val_loss'], '%.6f' % info['step'].max()\n",
      "    print '   '.join(i.ljust(max_len) for i in row)\n",
      "    \n",
      "print time.time() - start"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#          loss       val loss\n",
        "------------------------------\n",
        "0          15.974117   15.869731   0.055171"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1          1.011753   0.928313   0.006093"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2          0.769431   0.717922   0.004118"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3          0.660601   0.623307   0.003293"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4          0.595488   0.566527   0.002767"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5          0.550810   0.527494   0.002367"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6          0.517588   0.498432   0.002043"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7          0.491588   0.475657   0.001773"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8          0.470495   0.457153   0.001546"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9          0.452916   0.441712   0.001352"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "100.356611967"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_predict = m.function(['inpt'], T.argmax(m.exprs['output_in'], axis=1))\n",
      "\n",
      "TY = f_predict(TX)\n",
      "\n",
      "print '#wrong', (TY != TZ.argmax(axis=1)).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#wrong 1078\n"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}